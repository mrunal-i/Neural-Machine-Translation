{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZfqzG-psHbd"
      },
      "source": [
        "# **Neural Machine Translation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9GBwu1PsSR3"
      },
      "source": [
        "We build a neural machine translation model based on the sequence-to-sequence (seq2seq) models proposed by Sutskever et al., 2014 and Cho et al., 2014. The seq2seq model is widely used in Machine Translation systems such as Google’s neural machine translation system (GNMT) (Wu et al., 2016).\n",
        "\n",
        "3 files are required for this project:\n",
        "1. **data.30.vi** - a file where each line contains a Vietnamese sentence to be translated (i.e. the source sentences)\n",
        "2. **data.30.en** - a file where each line contains an English sentence corresponding to the Vietnamese sentence in the same line position. (i.e. the target sentences)\n",
        "3. **nmt_model_keras.py** - code for this project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyDvxbvTt70n"
      },
      "source": [
        "##**LanguageDict**\n",
        "\n",
        "LanguageDict is a class for creating language dict objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtHvI1pGvMBG"
      },
      "source": [
        "## **The load_dataset() Method**\n",
        "\n",
        "This helper method reads from the source and target files to load max_num_examples sentences, split those sentences into train, development and test sets, and return relevant data.\n",
        "\n",
        "As an example of the ouput returned by this code, let's assume we are translating the sentence 'I like rabbits' from English to English (this of course is never the case), such that the tokenised and case-normalised source sentence list and target sentence list are as follows:\n",
        "\n",
        "\n",
        "```\n",
        "# In Vietnamese this would actually be [['tôi', 'thích', 'thỏ']].\n",
        "# We will use English to English here using the following code.\n",
        "source_words = [['i', 'like', 'rabbits']]\n",
        "target_words = [['i', 'like', 'rabbits']]\n",
        "```\n",
        "The word2ids for the source and target language dictionaries look as follows:\n",
        "```\n",
        "source_dict.word2ids = {'<PAD>': 0, '<UNK>': 1, 'i': 2, 'like': 3, 'rabbits':4}\n",
        "\n",
        "# end and start tokens are added to the target words\n",
        "target_dict.word2ids = {'<PAD>': 0, '<UNK>': 1, '<start>': 2, 'i': 3, 'like': 4, 'rabbits':5, '<end>':6}\n",
        "\n",
        "```\n",
        "Let's also assume that we are training and testing on this dataset of one sentence.\n",
        "The **source words** for train/dev/test will be given as follows:\n",
        "```\n",
        "# [batch_size X max_sent_length]\n",
        "source_words_train = [[2,3,4]] # corresponding to ['i', 'like', 'rabbits']\n",
        "source_words_dev = [[2,3,4]]  # corresponding to ['i', 'like', 'rabbits']\n",
        "source_words_test = [[2,3,4]] # corresponding to ['i', 'like', 'rabbits']\n",
        "```\n",
        "\n",
        "The **target words** for the train data will be given as follows (dev/test do not need target words as the model will generate those):\n",
        "```\n",
        "target_words_train = [[2,3,4,5]] # corresponding to ['<start>', 'i', 'like', 'rabbits']\n",
        "```\n",
        "\n",
        "The **target words labels** for each word will be the next word. The target word labels for train/dev/test data will be given as follows\n",
        "```\n",
        "target_words_train_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
        "target_words_dev_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
        "target_words_test_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
        "```\n",
        "The dimensions for the train target words labels would be expanded to have the following dimentionality:\n",
        "```\n",
        "# [batch_size X max_sent_length array X 1]\n",
        "[[3], [4], [5], [6]]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc8KZaJn3uBK"
      },
      "source": [
        "##**Neural Translation Model (NMT)**\n",
        "\n",
        "For NMT, the network (a system of connected layers/models) used for training differs slightly from the network used for inference. Both use the encoder-decoder architecture.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "\n",
        "This code snippet outlines the implementation of a Neural Machine Translation (NMT) model, which consists of an encoder-decoder architecture with attention mechanism. The tasks are divided into three parts:\n",
        "1. Task 1: Implementing the Encoder\n",
        "   - Embedding Lookup: Two embedding layers are created for the source and target languages to convert input word indices into dense vectors.\n",
        "   - Encoder LSTM: An LSTM layer is utilized to process the embedded source words, producing encoder outputs and final states.\n",
        "\n",
        "2. Task 2: Implementing the Decoder and the Inference Loop\n",
        "   - Get Decoder Outputs: The decoder LSTM is employed to generate outputs during inference using the initial states from the encoder. The outputs are optionally passed through an attention layer and a dense layer to obtain the final predicted outputs.\n",
        "\n",
        "3. Task 3: Adding Attention\n",
        "   - Attention Calculation: Attention scores are computed using the dot product between decoder and encoder outputs, followed by the softmax function to obtain attention weights.\n",
        "   - Context Vector: A context vector is generated by taking the weighted sum of encoder outputs based on attention weights.\n",
        "   - Concatenation with Decoder Outputs: The context vector is concatenated with the decoder outputs to incorporate context information during decoding.\n",
        "\n",
        "The model's performance is evaluated on a development set and a test set, yielding a BLEU score of 8.04 on the test set. The training time for the model is approximately 45 minutes and 53 seconds. Additionally, warnings regarding tokenization issues are addressed to ensure accurate evaluation. Overall, the NMT model demonstrates effective translation capabilities with attention mechanism integration."
      ],
      "metadata": {
        "id": "YGHci6fD1QMn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgtz6XAl4E8D"
      },
      "source": [
        "###**Training mode**\n",
        "\n",
        "**Encoder**\n",
        "\n",
        "Given:\n",
        "- `source_words`: a `batch_size(num_sents) x max_sentence_length` array representing the source words. In our mini example, this would be the Vietnamese equivalent of `['i', 'like', 'rabbits']`, i.e. `[['tôi', 'thích', 'thỏ']]`.\n",
        "\n",
        "The following steps comprise the encoder network:\n",
        "\n",
        "1. Transform `source_words` into `source_words_embeddings` using a randomly initialized embedding lookup. `source_words_embeddings` is thus an array with the shape `batch_size(num_sents) x max_sentence_length x embedding_dim`.\n",
        "2. Apply embedding dropout with `embedding_dropout_rate`.\n",
        "3. Use a single `LSTM` with the `hidden_size` units to learn a representation for the source words i.e. to encode the input.\n",
        "\n",
        "    (a.) The hidden and cell states for this `LSTM` are initialized to zeros (i.e. we leave the `initial_state = None` default as is).\n",
        "\n",
        "    (b.) We save the `encoder_outputs` (the sequence not just the last state); and the encoder (hidden and cell) states.\n",
        "\n",
        "This way, the model encodes a representation for the source words. Task 1 guides you to complete the encoder part of the training model.\n",
        "\n",
        "\n",
        "**Decoder (No Attention)**\n",
        "\n",
        "Given:\n",
        "- `target_words`: a `batch_size(i.e. num_sents in batch) x max_sentence_length` array representing the target words. This is a time shifted translation of the source words with an added (prepended) `<START>` token `['<start>', 'i', 'like', 'rabbits']`.\n",
        "\n",
        "The decoding is done in the following steps:\n",
        "\n",
        "1. Transform `target_words` into `target_words_embeddings` using a randomly initialized embedding lookup. `target_words_embeddings` is thus an array with the shape `batch_size x max_sentence_length x embedding_dim`.\n",
        "\n",
        "2. Apply embedding dropout of `embedding_dropout_rate`.\n",
        "\n",
        "3. Use a single `LSTM` with `hidden_size` units to learn a representation for the target words. The context is given to this model by using the encoder states to initialise the decoder LSTM. For example, the encoder state for `'thỏ'` (last word in the input sequence, its hidden representation summarises the sentence) is used to learn the representation for the `'<start>'` token.\n",
        "\n",
        "4. For each token representation, we use a dense layer to output a `target_vocab_size` vector of probabilities to be the next word following the represented token. The output `decoder_outputs_train` is thus an array  with the shape `batch_size x max_sent_length + 1 x target_vocab_size`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4tsMpCYJUk1"
      },
      "source": [
        "###**Inference Mode**\n",
        "\n",
        "**Encoder**\n",
        "\n",
        "The inference time encoding follows the same steps as the training time encoding.\n",
        "\n",
        "\n",
        "**Decoder (No attention)**\n",
        "\n",
        "During training time, we passed a `batch_size(num_sents) x max_sentence_length` array representing the target words into the decoder LSTM. The `decoder_lstm` represents the given target sentence using the context from the encoder LSTM (representation for the source sentence).  \n",
        "\n",
        "At test time, several things are different:\n",
        "\n",
        "1. We no longer have access to a complete translation of the source sentence (recall that no `target_words` arrays exist for dev and test sets). Rather we initialise the target words array as follows:\n",
        "\n",
        "    Each expected target sentence contains only a single token index, the index of the `'<start>'` token. So, the target_word_dev/test is a `batch_size x 1` array (see the nmt.eval() function).\n",
        "\n",
        "2. This `batch_size x 1` array is fed to the trained `decoder_lstm` and the predicted array is a `batch_size x 1 x target_vocab_size` such that taking the argmax of this array across the dimension 2 will give the most probable next word.\n",
        "\n",
        "For example, at time_step 0 (first time step) the `step_target_words` is given. It is a `batch_size x 1` array containing the `'<start>'` token. The next word prediction of the decoder is for each sentence (in the batch) the first actual word.\n",
        "\n",
        "\n",
        "At the first time step, the `decoder_lstm` still uses the `encoder_states` as its initial states. At subsequent time steps, it uses its own states from the previous time steps. We hence loop over time steps to generate a new word at a time.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V5YoFP3yQO-",
        "outputId": "69ba92aa-cd1d-4a3a-8d4f-d956bca45442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "upXa_erqyzKm"
      },
      "outputs": [],
      "source": [
        "# change this to the path to your folder. Remember to start from the home directory\n",
        "PATH = 'MyDrive/Neural_Networks_Activity_1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ffbGcgrRy7p6"
      },
      "outputs": [],
      "source": [
        "PATH_TO_FOLDER = \"/content/drive/\" + PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XfSgKakK0QgV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(PATH_TO_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NmSgv44y0TN9"
      },
      "outputs": [],
      "source": [
        "SOURCE_PATH = PATH_TO_FOLDER + '/data.30.vi'\n",
        "TARGET_PATH = PATH_TO_FOLDER + '/data.30.en'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "273YkXga27zD"
      },
      "source": [
        "Let's install the Sacrebleu (https://github.com/mjpost/sacrebleu) package for BLEU computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6ai1zDFZgMy",
        "outputId": "20eb3287-0dad-4d1e-96ac-fe15962db423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OOTMtc_l0_ut"
      },
      "outputs": [],
      "source": [
        "import nmt_model_keras as nmt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IsO7wW6U1w2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3209b1-5302-4802-f1ce-e419c8c05ae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading dictionaries\n",
            "read 24000/3000/3000 train/dev/test batches\n",
            "number of tokens in source: 2034, number of tokens in target:2506\n",
            "Task 1(a): Creating the embedding lookups...\n",
            "\n",
            "Task 1(b): Looking up source and target words...\n",
            "\n",
            "Task 1(c): Creating an encoder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\t\t\t\t Train Model Summary.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 100)            203400    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 100)            250600    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, None, 100)            0         ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 100)            0         ['embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, None, 200),          240800    ['dropout[0][0]']             \n",
            "                              (None, 200),                                                        \n",
            "                              (None, 200)]                                                        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 200),          240800    ['dropout_1[0][0]',           \n",
            "                              (None, 200),                           'lstm[0][1]',                \n",
            "                              (None, 200)]                           'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 2506)           503706    ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1439306 (5.49 MB)\n",
            "Trainable params: 1439306 (5.49 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         203400    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 100)         0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, None, 200),       240800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 444200 (1.69 MB)\n",
            "Trainable params: 444200 (1.69 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            " Putting together the decoder states\n",
            "\t\t\t\t\t\t Decoder Inference Model summary\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 100)            250600    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 100)            0         ['embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 200)]                0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 200)]                0         []                            \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 200),          240800    ['dropout_1[0][0]',           \n",
            "                              (None, 200),                           'input_3[0][0]',             \n",
            "                              (None, 200)]                           'input_4[0][0]']             \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)        [(None, None, 200)]          0         []                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 2506)           503706    ['lstm_1[1][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 995106 (3.80 MB)\n",
            "Trainable params: 995106 (3.80 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Starting training epoch 1/10\n",
            "240/240 [==============================] - 49s 159ms/step - loss: 5.1507 - accuracy: 0.1611\n",
            "Time used for epoch 1: 1 m 27 s\n",
            "Evaluating on dev set after epoch 1/10:\n",
            "30/30 [==============================] - 1s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 0.30\n",
            "Time used for evaluate on dev set: 0 m 13 s\n",
            "Starting training epoch 2/10\n",
            "240/240 [==============================] - 19s 79ms/step - loss: 4.4836 - accuracy: 0.2359\n",
            "Time used for epoch 2: 0 m 19 s\n",
            "Evaluating on dev set after epoch 2/10:\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 1.57\n",
            "Time used for evaluate on dev set: 0 m 12 s\n",
            "Starting training epoch 3/10\n",
            "240/240 [==============================] - 17s 69ms/step - loss: 4.2009 - accuracy: 0.2694\n",
            "Time used for epoch 3: 0 m 16 s\n",
            "Evaluating on dev set after epoch 3/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 6ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 1.27\n",
            "Time used for evaluate on dev set: 0 m 11 s\n",
            "Starting training epoch 4/10\n",
            "240/240 [==============================] - 16s 67ms/step - loss: 4.0309 - accuracy: 0.2876\n",
            "Time used for epoch 4: 0 m 16 s\n",
            "Evaluating on dev set after epoch 4/10:\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 2.38\n",
            "Time used for evaluate on dev set: 0 m 11 s\n",
            "Starting training epoch 5/10\n",
            "240/240 [==============================] - 15s 64ms/step - loss: 3.8827 - accuracy: 0.3077\n",
            "Time used for epoch 5: 0 m 20 s\n",
            "Evaluating on dev set after epoch 5/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 2.66\n",
            "Time used for evaluate on dev set: 0 m 12 s\n",
            "Starting training epoch 6/10\n",
            "240/240 [==============================] - 18s 73ms/step - loss: 3.7731 - accuracy: 0.3218\n",
            "Time used for epoch 6: 0 m 17 s\n",
            "Evaluating on dev set after epoch 6/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 6ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 2.96\n",
            "Time used for evaluate on dev set: 0 m 11 s\n",
            "Starting training epoch 7/10\n",
            "240/240 [==============================] - 15s 64ms/step - loss: 3.6756 - accuracy: 0.3352\n",
            "Time used for epoch 7: 0 m 15 s\n",
            "Evaluating on dev set after epoch 7/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 3.51\n",
            "Time used for evaluate on dev set: 0 m 11 s\n",
            "Starting training epoch 8/10\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 3.5855 - accuracy: 0.3471\n",
            "Time used for epoch 8: 0 m 15 s\n",
            "Evaluating on dev set after epoch 8/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 3.79\n",
            "Time used for evaluate on dev set: 0 m 12 s\n",
            "Starting training epoch 9/10\n",
            "240/240 [==============================] - 15s 64ms/step - loss: 3.5083 - accuracy: 0.3573\n",
            "Time used for epoch 9: 0 m 15 s\n",
            "Evaluating on dev set after epoch 9/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 4.43\n",
            "Time used for evaluate on dev set: 0 m 12 s\n",
            "Starting training epoch 10/10\n",
            "240/240 [==============================] - 15s 64ms/step - loss: 3.4402 - accuracy: 0.3646\n",
            "Time used for epoch 10: 0 m 20 s\n",
            "Evaluating on dev set after epoch 10/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 4.58\n",
            "Time used for evaluate on dev set: 0 m 12 s\n",
            "Training finished!\n",
            "Time used for training: 6 m 7 s\n",
            "Evaluating on test set:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 5.13\n",
            "Time used for evaluate on test set: 0 m 12 s\n"
          ]
        }
      ],
      "source": [
        "nmt.main(SOURCE_PATH, TARGET_PATH, use_attention=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlMDC3DJi12c"
      },
      "source": [
        "##**Training and Decoding with Attention**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cQKwvFqurVY"
      },
      "source": [
        "The inputs to the attention layer are encoder and decoder outputs. The attention mechanism:\n",
        "1. Computes a score (Luong's dot product attention score) for each source word\n",
        "2. Weights the encoder representations using these scores.\n",
        "3. Concatenates the weighted encoder representation with the decoder ouput.\n",
        "This new decoder output will now be the input to the `decoder_dense` layer.\n",
        "\n",
        "Step-by-step details for Task 3 are in the pdf file. Once you have completed this Task, you are ready to train with attention. Training time will be no more than 10 minutes using a GPU and you should get a test BLEU score of around 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "23t6wfpLkb2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15f0268-a98e-402f-c5c5-681a4141cb1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading dictionaries\n",
            "read 24000/3000/3000 train/dev/test batches\n",
            "number of tokens in source: 2034, number of tokens in target:2506\n",
            "Task 1(a): Creating the embedding lookups...\n",
            "\n",
            "Task 1(b): Looking up source and target words...\n",
            "\n",
            "Task 1(c): Creating an encoder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\t\t\t\t Train Model Summary.\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, None, 100)            203400    ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, None, 100)            0         ['embedding_2[0][0]']         \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, None, 100)            250600    ['input_7[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               [(None, None, 200),          240800    ['dropout_2[0][0]']           \n",
            "                              (None, 200),                                                        \n",
            "                              (None, 200)]                                                        \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, None, 100)            0         ['embedding_3[0][0]']         \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               [(None, None, 200),          240800    ['dropout_3[0][0]',           \n",
            "                              (None, 200),                           'lstm_2[0][1]',              \n",
            "                              (None, 200)]                           'lstm_2[0][2]']              \n",
            "                                                                                                  \n",
            " attention_layer (Attention  (None, None, 400)            0         ['lstm_2[0][0]',              \n",
            " Layer)                                                              'lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, None, 2506)           1004906   ['attention_layer[0][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1940506 (7.40 MB)\n",
            "Trainable params: 1940506 (7.40 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 100)         203400    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, None, 100)         0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               [(None, None, 200),       240800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 444200 (1.69 MB)\n",
            "Trainable params: 444200 (1.69 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            " Putting together the decoder states\n",
            "\t\t\t\t\t\t Decoder Inference Model summary\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, None, 100)            250600    ['input_7[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, None, 100)            0         ['embedding_3[0][0]']         \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)        [(None, 200)]                0         []                            \n",
            "                                                                                                  \n",
            " input_9 (InputLayer)        [(None, 200)]                0         []                            \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)       [(None, None, 200)]          0         []                            \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               [(None, None, 200),          240800    ['dropout_3[0][0]',           \n",
            "                              (None, 200),                           'input_8[0][0]',             \n",
            "                              (None, 200)]                           'input_9[0][0]']             \n",
            "                                                                                                  \n",
            " attention_layer (Attention  (None, None, 400)            0         ['input_10[0][0]',            \n",
            " Layer)                                                              'lstm_3[1][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, None, 2506)           1004906   ['attention_layer[1][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1496306 (5.71 MB)\n",
            "Trainable params: 1496306 (5.71 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Starting training epoch 1/10\n",
            "240/240 [==============================] - 34s 122ms/step - loss: 5.0486 - accuracy: 0.1800\n",
            "Time used for epoch 1: 0 m 34 s\n",
            "Evaluating on dev set after epoch 1/10:\n",
            "30/30 [==============================] - 1s 3ms/step\n",
            "30/30 [==============================] - 1s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 1.44\n",
            "Time used for evaluate on dev set: 0 m 14 s\n",
            "Starting training epoch 2/10\n",
            "240/240 [==============================] - 19s 80ms/step - loss: 4.3401 - accuracy: 0.2556\n",
            "Time used for epoch 2: 0 m 20 s\n",
            "Evaluating on dev set after epoch 2/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 1.64\n",
            "Time used for evaluate on dev set: 0 m 13 s\n",
            "Starting training epoch 3/10\n",
            "240/240 [==============================] - 16s 68ms/step - loss: 4.0594 - accuracy: 0.2889\n",
            "Time used for epoch 3: 0 m 16 s\n",
            "Evaluating on dev set after epoch 3/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 2.48\n",
            "Time used for evaluate on dev set: 0 m 13 s\n",
            "Starting training epoch 4/10\n",
            "240/240 [==============================] - 16s 67ms/step - loss: 3.8594 - accuracy: 0.3128\n",
            "Time used for epoch 4: 0 m 20 s\n",
            "Evaluating on dev set after epoch 4/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 3.32\n",
            "Time used for evaluate on dev set: 0 m 13 s\n",
            "Starting training epoch 5/10\n",
            "240/240 [==============================] - 17s 69ms/step - loss: 3.6946 - accuracy: 0.3343\n",
            "Time used for epoch 5: 0 m 20 s\n",
            "Evaluating on dev set after epoch 5/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 6ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 4.09\n",
            "Time used for evaluate on dev set: 0 m 12 s\n",
            "Starting training epoch 6/10\n",
            "240/240 [==============================] - 16s 66ms/step - loss: 3.5631 - accuracy: 0.3512\n",
            "Time used for epoch 6: 0 m 20 s\n",
            "Evaluating on dev set after epoch 6/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 5.02\n",
            "Time used for evaluate on dev set: 0 m 12 s\n",
            "Starting training epoch 7/10\n",
            "240/240 [==============================] - 16s 66ms/step - loss: 3.4372 - accuracy: 0.3674\n",
            "Time used for epoch 7: 0 m 15 s\n",
            "Evaluating on dev set after epoch 7/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 5.90\n",
            "Time used for evaluate on dev set: 0 m 13 s\n",
            "Starting training epoch 8/10\n",
            "240/240 [==============================] - 16s 69ms/step - loss: 3.3131 - accuracy: 0.3828\n",
            "Time used for epoch 8: 0 m 20 s\n",
            "Evaluating on dev set after epoch 8/10:\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 6.66\n",
            "Time used for evaluate on dev set: 0 m 12 s\n",
            "Starting training epoch 9/10\n",
            "240/240 [==============================] - 17s 69ms/step - loss: 3.1864 - accuracy: 0.3991\n",
            "Time used for epoch 9: 0 m 20 s\n",
            "Evaluating on dev set after epoch 9/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 7.51\n",
            "Time used for evaluate on dev set: 0 m 13 s\n",
            "Starting training epoch 10/10\n",
            "240/240 [==============================] - 15s 64ms/step - loss: 3.0642 - accuracy: 0.4142\n",
            "Time used for epoch 10: 0 m 15 s\n",
            "Evaluating on dev set after epoch 10/10:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 5ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 8.18\n",
            "Time used for evaluate on dev set: 0 m 13 s\n",
            "Training finished!\n",
            "Time used for training: 5 m 38 s\n",
            "Evaluating on test set:\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 8.27\n",
            "Time used for evaluate on test set: 0 m 12 s\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dot\n",
        "nmt.main(SOURCE_PATH, TARGET_PATH, use_attention=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Model Architecture**: An LSTM-based encoder-decoder architecture is used with attention mechanisms. This is a common setup for sequence-to-sequence tasks like translation.\n",
        "\n",
        "2. **Training Progress**: The training progresses through epochs, with each epoch updating the model's parameters to minimize the loss function. Each epoch takes a certain amount of time to complete, which seems reasonable given the complexity of the model and the size of the dataset.\n",
        "\n",
        "3. **Evaluation on Dev Set**: After each epoch, the model's performance is evaluated on a development set. This evaluation likely involves calculating metrics such as BLEU score to assess translation quality.\n",
        "\n",
        "4. **BLEU Scores**: The BLEU scores indicate how well the model is performing on the development set. As the training progresses, the BLEU scores are increasing, which suggests that the model is improving its translation quality over time.\n",
        "\n",
        "5. **Model BLEU Score**: The reported BLEU scores for the model are between 1.44 and 8.27, which indicates the quality of translations produced by the model. A higher BLEU score generally indicates better translation quality.\n",
        "\n",
        "Overall, it seems like the model is learning effectively and improving its translation quality over the training epochs."
      ],
      "metadata": {
        "id": "Hip9-tSjSOYU"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}